{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code did not function as intended and was updated in the hardcoded version with a pre-defined structure. the problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rvw8Hn75Q9EU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#!git clone https://github.com/greydanus/mnist1d\n",
    "#import mnist1d\n",
    "#from mnist1d.data import get_templates, get_dataset_args, get_dataset\n",
    "#from mnist1d.utils import set_seed, plot_signals, ObjectView, from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H16_IkWUb41l"
   },
   "outputs": [],
   "source": [
    "class DeepCNet(nn.Module):\n",
    "    \"\"\"\n",
    "    DeepCNet convolutional network setup\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, l, k):\n",
    "        super(DeepCNet, self).__init__()\n",
    "        \"\"\"\n",
    "        Generate the DeepCNet network\n",
    "\n",
    "        Args:\n",
    "          l : l+1 convolutional filters, l 2x2 max-pooling layers\n",
    "          k : number of conv filters in n-th conv layer = nk\n",
    "        \"\"\"\n",
    "        super(DeepCNet, self).__init__()\n",
    "        self.l = l\n",
    "        self.k = k\n",
    "\n",
    "        # input layer size N * N with N = 3 * (2 ** l)\n",
    "        self.N = 3 * (2 ** self.l)\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(l+1):\n",
    "            if i == 0:\n",
    "                self.layers.append(nn.Conv2d(1,self.k, 3))\n",
    "                self.layers.append(nn.ReLU())\n",
    "                self.layers.append(nn.MaxPool2d(2))\n",
    "            elif i == l:\n",
    "                self.layers.append(nn.Conv2d(i*self.k,self.k+i*self.k, 2))\n",
    "                self.layers.append(nn.Softmax(dim=2))\n",
    "            else:\n",
    "                self.layers.append(nn.Conv2d(i*self.k,self.k+i*self.k, 2))\n",
    "                self.layers.append(nn.ReLU())\n",
    "                self.layers.append(nn.MaxPool2d(2))\n",
    "        #self.layers = torch.stack(self.layers)\n",
    "        #print(self.layers)\n",
    "        #print(self.layers.shape)\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "            #x = x.view(x.size(0),-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJ3NW-Lscx2z",
    "outputId": "54c5fbe6-9116-4624-e814-63265f90b193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 600, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "DCN = DeepCNet(5, 100)\n",
    "\n",
    "x2 = torch.randn((1, 1, DCN.N, DCN.N), dtype=torch.float32)\n",
    "outcome_x2 = DCN(x2)\n",
    "#summary(DCN2,(1,1,DCN2.N,DCN2.N),device='cpu')\n",
    "print(outcome_x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4G7ur3FDONmQ"
   },
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"\n",
    "    If GPU is available, return torch.device as cuda:0; else return torch.device\n",
    "    as cpu.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65Ix0nDuRLgN"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_loader, net, device=torch.device('cpu')):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    net.eval()  #make sure network is in evaluation mode\n",
    "\n",
    "    #init\n",
    "    acc_sum = torch.tensor([0], dtype=torch.float32, device=device)\n",
    "    n = 0\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        # Copy the data to device.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y = y.long()\n",
    "            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))\n",
    "            n += y.shape[0] #increases with the number of samples in the batch\n",
    "    return acc_sum.item()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPbwyuWDNq8X",
    "outputId": "eb9b4615-0f11-4c21-9f63-d13ad9e4363f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UtBf6b7KRwre",
    "outputId": "371792fb-c450-4d8f-9e7c-857256d7f2af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1647,)\n",
      "(1647, 95, 95)\n",
      "(6588,)\n",
      "(6588, 95, 95)\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.load('/content/drive/My Drive/Colab Notebooks/testlabels95_183.npy')\n",
    "test_data = np.load('/content/drive/My Drive/Colab Notebooks/testdata95_183.npy')\n",
    "train_labels = np.load('/content/drive/My Drive/Colab Notebooks/traininglabels95_183.npy')\n",
    "train_data = np.load('/content/drive/My Drive/Colab Notebooks/trainingdata95_183.npy')\n",
    "print(test_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "tensors_train = torch.Tensor(train_data), torch.Tensor(train_labels).long()\n",
    "tensors_test = torch.Tensor(test_data), torch.Tensor(test_labels).long()\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(*tensors_train), batch_size=1000)\n",
    "test_loader = DataLoader(TensorDataset(*tensors_test), batch_size=1000)\n",
    "\n",
    "\n",
    "#train_loader = DataLoader(train_data, batch_size=10000)\n",
    "#test_loader = DataLoader(test_data, batch_size=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "rJEm5HuPRbem",
    "outputId": "e03c40c7-683b-44f0-c596-1981fc3db90f"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ff993d289777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepCNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#net.apply(weights_init)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-64f9d87e5242>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m#x = x.view(x.size(0),-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [20, 1, 3, 3], expected input[2, 20, 95, 95] to have 1 channels, but got 20 channels instead"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 2 \n",
    "\n",
    "# Initialize network\n",
    "l = 5\n",
    "k = 20\n",
    "net = DeepCNet(l,k)\n",
    "#net.apply(weights_init)\n",
    "summary(net,(20,95,95), device = 'cpu')\n",
    "print(net.parameters())\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "# How to create net.parameters()?\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define list to store losses and performances of each iteration\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Try using gpu instead of cpu\n",
    "device = try_gpu()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Network in training mode and to device\n",
    "    net.train()\n",
    "    net.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        # Set to same device\n",
    "       # y_batch = train_labels\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        #x_batch = x_batch.to(device)\n",
    "\n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        y_pred = net(x_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        # Backward computation and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute train and test error\n",
    "    train_acc = 100*evaluate_accuracy(train_loader, net.to('cpu'))\n",
    "    test_acc = 100*evaluate_accuracy(test_loader, net.to('cpu'))\n",
    "    \n",
    "    # Development of performance\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    # Print performance\n",
    "    print('Epoch: {:.0f}'.format(epoch+1))\n",
    "    print('Accuracy of train set: {:.00f}%'.format(train_acc))\n",
    "    print('Accuracy of test set: {:.00f}%'.format(test_acc))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reproducibility_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
